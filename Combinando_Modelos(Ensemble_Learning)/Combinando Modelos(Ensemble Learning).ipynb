{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ba6b43-6560-44c2-a925-67736526076a",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "### ‚úÖ O que √© Ensemble Learning?\n",
    "\n",
    "Ensemble Learning √© uma t√©cnica em que **v√°rios modelos diferentes trabalham juntos** para resolver um mesmo problema.\n",
    "\n",
    "Em vez de usar apenas um modelo de machine learning, usamos um **conjunto (ensemble)** deles.  \n",
    "A ideia √© simples: **‚Äúv√°rias cabe√ßas pensam melhor do que uma‚Äù.**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Para que serve?\n",
    "\n",
    "Ensemble Learning serve para:\n",
    "\n",
    "- **Aumentar a precis√£o** das previs√µes  \n",
    "- **Reduzir erros** cometidos por modelos individuais  \n",
    "- **Evitar overfitting**  \n",
    "- **Tornar o sistema mais robusto e confi√°vel**\n",
    "\n",
    "Em geral, um *ensemble* tem desempenho melhor do que qualquer modelo usado sozinho.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Como √© usado?\n",
    "\n",
    "Existem tr√™s formas principais de combinar modelos:\n",
    "\n",
    "---\n",
    "\n",
    "### ### 1. **Bagging** (ex.: Random Forest)\n",
    "\n",
    "- Treina v√°rios modelos **iguais**, cada um usando **partes diferentes dos dados**.\n",
    "- Depois, combina os resultados (m√©dia ou vota√ß√£o).\n",
    "- Ajuda a reduzir erro e overfitting.\n",
    "\n",
    "**Exemplo simples:**  \n",
    "‚ÄúTreinar v√°rias √°rvores de decis√£o diferentes e deixar elas votarem no resultado final.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Boosting** (ex.: XGBoost, AdaBoost)\n",
    "\n",
    "- Treina modelos **um ap√≥s o outro**.\n",
    "- Cada novo modelo tenta **corrigir os erros** do anterior.\n",
    "- Gera previs√µes muito precisas.\n",
    "\n",
    "**Exemplo simples:**  \n",
    "‚ÄúUm modelo aprende. Depois outro corrige os erros dele. Depois outro, e assim por diante.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Stacking**\n",
    "\n",
    "- Treina v√°rios modelos **diferentes** (ex.: √°rvore, rede neural, regress√£o).\n",
    "- Um **meta-modelo** final aprende qual deles funciona melhor em cada situa√ß√£o.\n",
    "\n",
    "**Exemplo simples:**  \n",
    "‚Äú√â como juntar opini√µes de especialistas e ter um ‚Äòespecialista-mestre‚Äô para decidir qual usar.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Resumo simples\n",
    "\n",
    "| Nome     | Ideia principal             | Analogia                                |\n",
    "|----------|-----------------------------|-------------------------------------------|\n",
    "| Bagging  | Combinar modelos iguais     | V√°rias pessoas votando                   |\n",
    "| Boosting | Um modelo corrige o outro   | Monitor explicando o erro do aluno       |\n",
    "| Stacking | Combinar modelos diferentes | Especialistas contribuindo com opini√µes  |\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Em poucas palavras\n",
    "\n",
    "**Ensemble Learning √© quando v√°rios modelos trabalham juntos para gerar uma previs√£o melhor do que fariam sozinhos.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182b3b2-4fd4-444a-a71a-92f03b06192b",
   "metadata": {},
   "source": [
    "# Vota√ß√£o Majorit√°ria (Hard Voting)\n",
    "\n",
    "### ‚úÖ O que √© o ‚ÄúClassificador por Vota√ß√£o Majorit√°ria (Hard Voting)‚Äù?\n",
    "\n",
    "O Hard Voting √© como fazer uma **elei√ß√£o entre v√°rios modelos**.\n",
    "\n",
    "Voc√™ usa v√°rios classificadores (ex.: √°rvore de decis√£o, SVM, KNN).  \n",
    "Cada um deles d√° sua opini√£o sobre qual √© a classe correta.\n",
    "\n",
    "Depois, voc√™ **conta os votos**.  \n",
    "A classe que recebe mais votos √© a escolhida.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Para que serve?\n",
    "\n",
    "Serve para **melhorar a precis√£o das previs√µes**, pois combinar v√°rios modelos geralmente produz um resultado melhor do que usar apenas um classificador.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Como funciona na pr√°tica?\n",
    "\n",
    "Imagine que voc√™ quer classificar se um e-mail √© *spam* ou *n√£o spam*.\n",
    "\n",
    "Voc√™ tem tr√™s modelos:\n",
    "\n",
    "- **Modelo A ‚Üí** spam  \n",
    "- **Modelo B ‚Üí** n√£o spam  \n",
    "- **Modelo C ‚Üí** spam  \n",
    "\n",
    "Agora contamos os votos:\n",
    "\n",
    "- spam ‚Üí 2 votos  \n",
    "- n√£o spam ‚Üí 1 voto  \n",
    "\n",
    "‚úîÔ∏è **Resultado final:** spam\n",
    "\n",
    "Simples assim.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Resumo super curto\n",
    "\n",
    "**Hard Voting = v√°rios modelos votam e a classe mais votada √© a resposta.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b002712-a8a9-45c9-b056-f9818b00cd8f",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 24px;\">\n",
    "Afirma√ß√£o: Isso s√≥ √© verdade se todos os classificadores forem perfeitamente independentes, cometendo erros n√£o correlacionados. Uma maneira de obter classificadores diversos √© trein√°-los usando algoritmos muito diferentes.\n",
    "</span>\n",
    "\n",
    "\n",
    "\n",
    "## Explica√ß√£o da afirma√ß√£o acima\n",
    "### ‚úÖ O que isso significa?\n",
    "\n",
    "Quando combinamos v√°rios classificadores, s√≥ teremos um grande ganho de desempenho se **eles errarem de jeitos diferentes**.\n",
    "\n",
    "Em outras palavras:\n",
    "\n",
    "- Se todos os modelos cometem **os mesmos erros**, combinar eles n√£o ajuda muito.  \n",
    "- Mas se **cada modelo erra coisas diferentes**, ent√£o quando um erra, outro acerta ‚Äî e a combina√ß√£o fica mais forte.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† O que significa ‚Äúerros independentes‚Äù?\n",
    "\n",
    "Significa que:\n",
    "\n",
    "- O erro de um modelo **n√£o depende** do erro do outro.  \n",
    "- Eles **n√£o pensam igual**, e por isso n√£o erram nas mesmas situa√ß√µes.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéØ Como conseguir modelos que erram de maneiras diferentes?\n",
    "\n",
    "Uma forma simples √© treinar modelos usando **algoritmos diferentes**.\n",
    "\n",
    "### Exemplos:\n",
    "\n",
    "- Uma **√°rvore de decis√£o** aprende de um jeito.  \n",
    "- Uma **rede neural** aprende de outro.  \n",
    "- Um **SVM** aprende de outro ainda.\n",
    "\n",
    "Como cada algoritmo funciona de forma diferente, eles tendem a errar em **coisas diferentes**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå Resumo simples\n",
    "\n",
    "Combinar modelos s√≥ funciona bem quando eles **n√£o cometem os mesmos erros**.  \n",
    "Para isso, usamos algoritmos diferentes, para que cada modelo traga uma **vis√£o diferente** do problema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443ac10-74c1-4470-8a8d-5dcf6417b8a8",
   "metadata": {},
   "source": [
    "# Vota√ß√£o Suave (Soft Voting)\n",
    "### ‚úÖ O que √© Soft Voting?\n",
    "\n",
    "Soft Voting √© uma forma de combinar v√°rios modelos usando **as probabilidades** que eles fornecem, e n√£o apenas o voto final.\n",
    "\n",
    "Em vez de cada modelo dizer ‚Äú√© A‚Äù ou ‚Äú√© B‚Äù, ele diz coisas como:\n",
    "\n",
    "- ‚ÄúTenho **70%** de certeza que √© A‚Äù\n",
    "- ‚ÄúTenho **30%** de certeza que √© B‚Äù\n",
    "\n",
    "O m√©todo pega essas probabilidades, **faz a m√©dia** e escolhe a classe com maior probabilidade m√©dia.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Como funciona na pr√°tica?\n",
    "\n",
    "Imagine que voc√™ quer decidir se um e-mail √© *spam* ou *n√£o spam*.\n",
    "\n",
    "Tr√™s modelos deram as seguintes probabilidades:\n",
    "\n",
    "| Modelo | Prob. Spam | Prob. N√£o Spam |\n",
    "|--------|------------|----------------|\n",
    "| A      | 0.70       | 0.30           |\n",
    "| B      | 0.60       | 0.40           |\n",
    "| C      | 0.80       | 0.20           |\n",
    "\n",
    "Agora fazemos a m√©dia:\n",
    "\n",
    "- **M√©dia Spam** = (0.70 + 0.60 + 0.80) / 3 = **0.70**  \n",
    "- **M√©dia N√£o Spam** = (0.30 + 0.40 + 0.20) / 3 = **0.30**\n",
    "\n",
    "‚úîÔ∏è **Resultado final: spam**\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Por que √© melhor que Hard Voting?\n",
    "\n",
    "Porque o Soft Voting usa o **n√≠vel de confian√ßa** de cada modelo.  \n",
    "Assim, um modelo muito confiante pesa mais do que um pouco confiante.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Resumo super simples\n",
    "\n",
    "**Soft Voting = combinar modelos usando probabilidades e escolher a classe com maior probabilidade m√©dia.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214c3d4-40ce-44ba-87af-9ffae8f9c243",
   "metadata": {},
   "source": [
    "## ‚úÖ Sintaxe b√°sica\n",
    "\n",
    "A fun√ß√£o do scikit-learn √© escrita assim:\n",
    "\n",
    "```python\n",
    "VotingClassifier(\n",
    "    estimators,\n",
    "    voting='hard',\n",
    "    weights=None,\n",
    "    n_jobs=None,\n",
    "    flatten_transform=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7e62c-2436-4426-94a8-1485eb368ba2",
   "metadata": {},
   "source": [
    "### üü¶ 1. `estimators`\n",
    "\n",
    "#### üëâ O que √©?\n",
    "\n",
    "√â uma **lista** contendo o **nome** e o **modelo** de cada classificador que voc√™ quer combinar.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Ideia\n",
    "\n",
    "‚Äú**Quais modelos v√£o votar?**‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úîÔ∏è Exemplo\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef78090-9c3f-4b15-b3fc-29f082e71337",
   "metadata": {},
   "source": [
    "### üü¶ 2. `voting`\n",
    "\n",
    "#### üëâ O que √©?\n",
    "\n",
    "Define **como os modelos v√£o votar**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéØ Valores poss√≠veis\n",
    "\n",
    "- **`'hard'`** ‚Üí cada modelo d√° um voto (classe final por maioria)\n",
    "- **`'soft'`** ‚Üí usa as probabilidades dos modelos e faz a m√©dia\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úîÔ∏è Exemplo\n",
    "\n",
    "```python\n",
    "VotingClassifier(estimators, voting='soft')   # Usa probabilidades\n",
    "VotingClassifier(estimators, voting='hard')   # Maioria simples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573f70a-9519-4347-8318-1e6a6e5c6f8e",
   "metadata": {},
   "source": [
    "### üü¶ 3. `weights`\n",
    "\n",
    "##### üëâ O que √©?\n",
    "\n",
    "√â uma **lista de pesos** que define a **influ√™ncia de cada modelo** na vota√ß√£o.\n",
    "\n",
    "- **Pesos maiores = modelo com mais influ√™ncia na decis√£o**\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Quando funciona?\n",
    "\n",
    "- Quando `voting='soft'`  \n",
    "- Ou quando `voting='hard'` mas voc√™ quer **ponderar os votos**\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úîÔ∏è Exemplo\n",
    "\n",
    "Dar mais peso √† Regress√£o Log√≠stica:\n",
    "\n",
    "```python\n",
    "VotingClassifier(\n",
    "    estimators,\n",
    "    voting='soft',\n",
    "    weights=[3, 1, 1]  # LR vale mais que os outros\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8847266-d139-42c5-8b02-99641ed466f2",
   "metadata": {},
   "source": [
    "### üü¶ 4. `n_jobs`\n",
    "\n",
    "### üëâ O que √©?\n",
    "\n",
    "Define o **n√∫mero de n√∫cleos da CPU** usados simultaneamente para treinar os modelos (paraleliza√ß√£o).\n",
    "\n",
    "---\n",
    "\n",
    "#### üéØ Valores poss√≠veis\n",
    "\n",
    "- **`None`** ‚Üí usa **1 n√∫cleo**\n",
    "- **`-1`** ‚Üí usa **todos os n√∫cleos dispon√≠veis**\n",
    "- **`2`, `4`, ...** ‚Üí usa um n√∫mero espec√≠fico de n√∫cleos\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úîÔ∏è Exemplo\n",
    "\n",
    "```python\n",
    "VotingClassifier(estimators, n_jobs=-1)  # usar m√∫ltiplos n√∫cleos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5595bd-73fa-4019-a132-99477428fab6",
   "metadata": {},
   "source": [
    "### üü¶ 5. `flatten_transform`\n",
    "\n",
    "#### üëâ O que √©?\n",
    "\n",
    "Par√¢metro usado quando voc√™ aplica o m√©todo `.transform()` do ensemble.\n",
    "\n",
    "- **`True`** ‚Üí concatena os outputs de todos os modelos em um √∫nico array  \n",
    "- **`False`** ‚Üí mant√©m os outputs separados\n",
    "\n",
    "Geralmente, voc√™ **n√£o precisa alterar** esse par√¢metro.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úîÔ∏è Exemplo\n",
    "\n",
    "```python\n",
    "VotingClassifier(estimators, flatten_transform=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b69d7-c1fc-4c65-8a77-8352a6db2bc4",
   "metadata": {},
   "source": [
    "### üü¶ 6. `verbose`\n",
    "\n",
    "#### üëâ O que √©?\n",
    "\n",
    "Controla se o modelo deve **mostrar mensagens extras** durante o treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéØ Valores poss√≠veis\n",
    "\n",
    "- **`0` ou `False`** ‚Üí modo silencioso  \n",
    "- **`1` ou `True`** ‚Üí imprime detalhes do processo\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úîÔ∏è Exemplo\n",
    "\n",
    "```python\n",
    "VotingClassifier(estimators, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e03328-025e-4868-a323-d237d2546a18",
   "metadata": {},
   "source": [
    "#### üéâ Exemplo completo e simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48427485-1fed-45ea-85ab-50268df05b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='soft',\n",
    "    weights=[2, 1, 1],   # LR tem mais peso\n",
    "    n_jobs=-1,           # usar todos os n√∫cleos\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24f4b0-8fc5-4c3b-98e5-71646d655a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
