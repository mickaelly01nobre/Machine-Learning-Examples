{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício de Programação: Regressão Logística e Softmax com MNIST\n",
    "\n",
    "Neste exercício, você aplicará os conceitos de Regressão Logística para classificação binária e Regressão Softmax para classificação multiclasse. Usaremos o famoso dataset MNIST, que consiste em imagens de dígitos manuscritos.\n",
    "\n",
    "**Objetivos:**\n",
    "1. Treinar um classificador binário para identificar se um dígito é '5' ou 'não-5'.\n",
    "2. Treinar um classificador multiclasse para identificar os dígitos de 0 a 9.\n",
    "3. Avaliar a performance de ambos os modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação do Ambiente e Carregamento dos Dados\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias e carregar o dataset MNIST.\n",
    "\n",
    "Também vamos pré-processar os dados: \n",
    "- Dividir em conjuntos de treino e teste.\n",
    "- Escalar os valores dos pixels para melhorar a performance do gradiente descendente.\n",
    "- Remodelar as imagens de 28x28 para vetores de 784 dimensões, que é o formato esperado por um classificador como `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato dos dados de treino: (1600, 64)\n",
      "Formato dos dados de teste: (197, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# carrega o dataset de dígitos manuscritos\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carregar o dataset MNIST\n",
    "digits = load_digits()\n",
    "# X contém os valores dos pixels (cada imagem é transformada em uma lista de 64 números).\n",
    "# y contém o rótulo (número real) de cada imagem (0 a 9).\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Dividir em conjuntos de treino e teste\n",
    "# Treino (X_train, y_train) → usado para ensinar o modelo (1600 exemplos).\n",
    "# Teste (X_test, y_test) → usado para verificar se ele aprendeu bem (restante dos exemplos).\n",
    "X_train, X_test = X[:1600], X[1600:]\n",
    "y_train, y_test = y[:1600], y[1600:]\n",
    "\n",
    "# Escalar os pixels\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Remodelar as imagens para vetores 1D (28*28 = 784)\n",
    "# reshape “achata” as imagens em vetores de uma única linha (1D).\n",
    "# Como cada imagem é 8x8, ela vira um vetor com 64 valores.\n",
    "# Isso é necessário porque a regressão logística espera vetores, não imagens 2D.\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(f\"Formato dos dados de treino: {X_train_flat.shape}\")\n",
    "print(f\"Formato dos dados de teste: {X_test_flat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Treinando um Classificador Binário (5 ou não-5)\n",
    "\n",
    "Agora, vamos criar um classificador para uma tarefa binária: detectar se um dígito é o número 5 ou não. Para isso, precisamos ajustar nossos rótulos (`y_train` e `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regressão Logística treinado!\n"
     ]
    }
   ],
   "source": [
    "# Criar os rótulos para a classificação binária (True para 5, False para outros)\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# SEU CÓDIGO AQUI: Treine o modelo usando o conjunto de treinamento (X_train_flat, y_train_5)\n",
    "\n",
    "# O parâmetro max_iter=1000 serve para garantir que o modelo tenha iterações suficientes para \n",
    "# convergir (ou seja, aprender bem).\n",
    "# Usamos max_iter=1000 para garantir a convergência\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# ----------------\n",
    "\n",
    "print(\"Modelo de Regressão Logística treinado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Classificador Binário\n",
    "\n",
    "Com o modelo treinado, vamos avaliar sua acurácia no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do classificador '5 ou não-5': 0.9848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# SEU CÓDIGO AQUI: Faça as previsões no conjunto de teste e calcule a acurácia.\n",
    "# Dica: Você pode usar o método .score() do modelo, que faz isso diretamente.\n",
    "\n",
    "# ----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinando um Classificador Multiclasse (Regressão Softmax)\n",
    "\n",
    "O `LogisticRegression` do Scikit-Learn automaticamente lida com a classificação multiclasse usando a estratégia \"um-contra-o-resto\" (OvR) por padrão. Para usar a Regressão Softmax (também chamada de Regressão Logística Multinomial), podemos definir o argumento `multi_class='multinomial'`.\n",
    "\n",
    "Vamos treinar um novo modelo para classificar todos os 10 dígitos (0 a 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regressão Softmax treinado!\n"
     ]
    }
   ],
   "source": [
    "# SEU CÓDIGO AQUI: Treine o modelo softmax usando o conjunto de treinamento com todas as classes (X_train_flat, y_train).\n",
    "\n",
    "# Inicializar o modelo de Regressão Softmax\n",
    "# Usamos max_iter=1000 para garantir a convergência.\n",
    "\n",
    "# ----------------\n",
    "\n",
    "print(\"Modelo de Regressão Softmax treinado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Classificador Multiclasse\n",
    "\n",
    "Por fim, avaliamos o modelo multiclasse no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do classificador multiclasse (Softmax): 0.9188\n"
     ]
    }
   ],
   "source": [
    "# SEU CÓDIGO AQUI: Calcule e imprima a acurácia do modelo multiclasse no conjunto de teste.\n",
    "\n",
    "# ----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Parabéns! Você implementou e avaliou com sucesso dois tipos de classificadores lineares:\n",
    "1. Um classificador de Regressão Logística para uma tarefa binária.\n",
    "2. Um classificador de Regressão Softmax para uma tarefa multiclasse.\n",
    "\n",
    "Você deve notar que, embora simples, esses modelos já alcançam uma acurácia razoavelmente alta para o reconhecimento de dígitos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
